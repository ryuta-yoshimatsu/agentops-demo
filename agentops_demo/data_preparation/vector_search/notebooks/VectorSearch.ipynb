{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Databricks notebook source\n",
        "#%pip install -r ../../data_prep_requirements.txt\n",
        "#dbutils.library.restartPython()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
        "# To disable autoreload; run %autoreload 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "################################################################################### \n",
        "# Vector Search\n",
        "#\n",
        "# This notebook creates a Vector Search index from a table containing chunked documents.\n",
        "#\n",
        "# Parameters:\n",
        "# * uc_catalog (required)                     - Name of the Unity Catalog \n",
        "# * schema (required)                         - Name of the schema inside Unity Catalog \n",
        "# * preprocessed_data_table (required)        - Name of the preprocessed data table inside database of Unity Catalog\n",
        "# * vector_search_endpoint (required)         - Name of the Vector Search endpoint\n",
        "# * bundle_root (required)                    - Root of the bundle\n",
        "#\n",
        "# Widgets:\n",
        "# * Vector Search endpoint: Text widget to input the name of the Vector Search endpoint\n",
        "# * Unity Catalog: Text widget to input the name of the Unity Catalog\n",
        "# * Schema: Text widget to input the name of the database inside the Unity Catalog\n",
        "# * Preprocessed data table: Text widget to input the name of the preprocessed data table inside the database of Unity Catalog\n",
        "# * Root of bundle: Text widget to input the root of the bundle\n",
        "#\n",
        "# Usage:\n",
        "# 1. Set the appropriate values for the widgets.\n",
        "# 2. Run the pipeline to set up the vector search endpoint.\n",
        "# 3. Create index.\n",
        "#\n",
        "##################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# List of input args needed to run this notebook as a job.\n",
        "# Provide them via DB widgets or notebook arguments in your DAB resources.\n",
        "\n",
        "# A Unity Catalog location containing the input data\n",
        "dbutils.widgets.text(\n",
        "    \"uc_catalog\",\n",
        "    \"agentops_stacks_dev\",\n",
        "    label=\"Unity Catalog\",\n",
        ")\n",
        "# Name of schema\n",
        "dbutils.widgets.text(\n",
        "    \"schema\",\n",
        "    \"agentops\",\n",
        "    label=\"Schema\",\n",
        ")\n",
        "# Name of preprocessed data table\n",
        "dbutils.widgets.text(\n",
        "    \"preprocessed_data_table\",\n",
        "    \"databricks_documentation\",\n",
        "    label=\"Preprocessed data table\",\n",
        ")\n",
        "# A Vector Search Endpoint for retrieving processed data\n",
        "dbutils.widgets.text(\n",
        "    \"vector_search_endpoint\",\n",
        "    \"ai_agent_endpoint\",\n",
        "    label=\"Vector Search endpoint\",\n",
        ")\n",
        "# Bundle root\n",
        "dbutils.widgets.text(\n",
        "    \"bundle_root\",\n",
        "    \"/\",\n",
        "    label=\"Root of bundle\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vector_search_endpoint = dbutils.widgets.get(\"vector_search_endpoint\")\n",
        "uc_catalog = dbutils.widgets.get(\"uc_catalog\")\n",
        "schema = dbutils.widgets.get(\"schema\")\n",
        "preprocessed_data_table = dbutils.widgets.get(\"preprocessed_data_table\")\n",
        "bundle_root = dbutils.widgets.get(\"bundle_root\")\n",
        "\n",
        "assert vector_search_endpoint != \"\", \"vector_search_endpoint notebook parameter must be specified\"\n",
        "assert uc_catalog != \"\", \"uc_catalog notebook parameter must be specified\"\n",
        "assert schema != \"\", \"schema notebook parameter must be specified\"\n",
        "assert preprocessed_data_table != \"\", \"preprocessed_data_table notebook parameter must be specified\"\n",
        "assert bundle_root != \"\", \"bundle_root notebook parameter must be specified\"\n",
        "\n",
        "# Updating to bundle root\n",
        "import sys \n",
        "\n",
        "root = dbutils.widgets.get(\"bundle_root\")\n",
        "sys.path.append(root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize endpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from databricks.vector_search.client import VectorSearchClient\n",
        "from data_preparation.vector_search.vector_search_utils.utils import vs_endpoint_exists, wait_for_vs_endpoint_to_be_ready\n",
        "\n",
        "vsc = VectorSearchClient(disable_notice=True)\n",
        "\n",
        "if not vs_endpoint_exists(vsc, vector_search_endpoint):\n",
        "    vsc.create_endpoint(name=vector_search_endpoint, endpoint_type=\"STANDARD\")\n",
        "\n",
        "# this may throw an error on the first pass, once the endpoint is created we'd see correct messages\n",
        "wait_for_vs_endpoint_to_be_ready(vsc, vector_search_endpoint)\n",
        "print(f\"Endpoint named {vector_search_endpoint} is ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from data_preparation.vector_search.vector_search_utils.utils import index_exists, wait_for_index_to_be_ready\n",
        "from databricks.sdk import WorkspaceClient\n",
        "import databricks.sdk.service.catalog as c\n",
        "\n",
        "# The table we'd like to index\n",
        "source_table_fullname = f\"{uc_catalog}.{schema}.{preprocessed_data_table}\"\n",
        "\n",
        "# Where we want to store our index\n",
        "vs_index_fullname = f\"{uc_catalog}.{schema}.{preprocessed_data_table}_vs_index\"\n",
        "\n",
        "if not index_exists(vsc, vector_search_endpoint, vs_index_fullname):\n",
        "  print(f\"Creating index {vs_index_fullname} on endpoint {vector_search_endpoint}...\")\n",
        "  vsc.create_delta_sync_index(\n",
        "    endpoint_name=vector_search_endpoint,\n",
        "    index_name=vs_index_fullname,\n",
        "    source_table_name=source_table_fullname,\n",
        "    pipeline_type=\"TRIGGERED\",\n",
        "    primary_key=\"id\",\n",
        "    embedding_source_column=\"content\", # The column containing our text\n",
        "    embedding_model_endpoint_name=\"databricks-gte-large-en\" # The embedding endpoint used to create the embeddings\n",
        "  )\n",
        "  #Let's wait for the index to be ready and all our embeddings to be created and indexed\n",
        "  vsc.get_index(vector_search_endpoint, vs_index_fullname).wait_until_ready()\n",
        "else:\n",
        "  #Trigger a sync to update our vs content with the new data saved in the table\n",
        "  vsc.get_index(vector_search_endpoint, vs_index_fullname).sync()\n",
        "\n",
        "print(f\"Index {vs_index_fullname} on table {source_table_fullname} is ready\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test if Index Online\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import databricks \n",
        "import time\n",
        "from data_preparation.vector_search.vector_search_utils.utils import check_index_online\n",
        "\n",
        "vector_index=vsc.get_index(endpoint_name=vector_search_endpoint, index_name=vs_index_fullname)\n",
        "\n",
        "check_index_online(vs_index_fullname, vector_index)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}